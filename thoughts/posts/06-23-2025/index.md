---
title: "On Education"
description: ""
author:
  - name: Jason Hawkins
date: "2025-06-23"
categories: [Pedagogy, AI]
image: banner.jpg
format: 
  html:
    toc: true
---

> In this new state, with a simple and solitary life, very limited needs, and the implements they had invented to provide for them, since men enjoyed very great leisure, they used it to procure many kinds of commodities unknown to their Fathers; and that was the first yoke they imposed on themselves without thinking about it, and the first source of the evils they prepared for their Descendants. For, besides their continuing thus to soften body and mind, as these commodities had lost almost all their pleasantness through habit, and as they had at the same time degenerated into true needs, being deprived of them became much more cruel than possessing them was sweet; and people were unhappy to lose them without being happy to possess them.

Excerpt from J.-J. Rousseau, Discourse on the Origin and Foundations of Inequality among Men (trans. by Roger Masters). Part II

I, like many educators, have been giving careful thought to the role of artificial intelligence (AI) in the classroom. Specifically, what is the role of large language models (LLMs) like ChatGPT and Claude? The above is a quote I heard from Rousseau on one of my favourite podcasts, EconTalk. The host, Ross Roberts, also notes that his favourite economists/moral philosopher Adam Smith had something to say on the topic of technology, too. In The Theory of Moral Sentiments, Smith points out that a person will acquire an expensive watch that does a slightly better job at keeping time, but it doesn't mean that person will will by any less tardy for meetings. 

Another of my favourite podcast hosts, Nate Hagens, had the philosopher of education Zak Stein on his show and raised some excellent points that shaped my thinking on the subject. His arguments around AI and education parallel those of Daron Acemoglu and other on AI and jobs - technology should build upon human capacity and increase (or improve) our quality of life and social interactions. In many historical cases, technology accomplished these purposes. However, it questionable whether current advances in AI are creating more human interactions or supplanting human-human interactions. We risk nurturing an inability to connect with other humans, as we increasingly rely on AI for the development of young minds through both informal online interactions and the growing formal role of AI in education. Stein and Hagens in their conversation go so far as suggesting that cognitive aptitudes will be diminished in developed nations with access to AI, with those in developing nations dominating the future world due to their continued nurturing of critical thinking skills. However, they also raise concerns about the increased use of LLM in development work - replacing on-the-ground teachers with online AI alternatives.

Another source that has influenced my recent thinking on this topic is an article in The Walrus by the philosophy professor Troy Jollimore. He argues that the purpose of higher education is to train students in critical thinking and writing. Like him, I am an academic purist in my believ that it is not the purpose of the university to train students in technical tools to solve problems. Jollimore uses the analogy of The Magic Bag, a common theme across myths and fables, which gives the lesson that one should be careful what they wish for. I also agree with Jollimore that North American culture does not value intellectual pursuit, that "[t]hose who emphasize theory, study, and scholarship are often viewed as marooned in ivory towers with expertise that is mostly, if not entirely, spurious." As he says in his article, many students want to exit university with a degree but otherwise unaltered by the experience. This perspective is strongly influenced by the belief that university prepares students for their 'job' and overlooks its role in preparing them for 'life'. Specifically, but philosophically, education may not give you a bigger paycheque but will "give you access to a more rewarding life". What Jollimore says about health ethics I believe to also be true about engineering ethics. What do you do when you are asked to develop infrastructure that systematically restricts the access of other people? Or do you decline to build a pipeline that will contribute to climate change?

How to address the role of AI in the classroom? Like Jollimore, I don't think that having students complete all their work in the classroom under close supervision is the answer. Writing performed under the pressure of time in no subsitute for the careful refining of an idea over several weeks (though I am not naive to the fact that many of my students are subjecting themselves to similar constraints outside the classroom finishing their assignments at the last minute). I have no illusion that I can prevent students from using LLMs, nor is it my intention that they not use them. Rather, my measure of success is whether the use of LLMs in work is improving (or diminishing) the ability of students to think critically and build a strong internal life centered on personal wellbeing and curiosity. I sometimes wonder, if I was born a decade later, would I be on TikTok or still spending my evenings writing about Rousseau and Smith?